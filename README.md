# 🏥 Health Insurance Rate Data Engineering Pipeline

This project provides a modular, production-grade data engineering pipeline to ingest, transform, and enrich U.S. health insurance rate data using Spark and Python. It follows the Bronze → Silver → Gold architecture and includes optional orchestration using [Papermill](https://papermill.readthedocs.io/en/latest/).


## 📁 Folder Structure

```
health-insurance-rate-data-etl/
├── .gitignore
├── LICENSE                  # MIT license (see below)
├── README.md
├── requirements.txt
├── data/
│   ├── bronze/
│   ├── silver/
│   ├── gold/
│   └── meta_data_files/  
│ 
├── configurations/
│   └── config.json          # Paths and filenames config
│   ├── api_config.yaml      # API source configuration
│
├── notebooks/               # Jupyter notebooks for each pipeline stage
│   ├── ingest_bronze.ipynb
│   ├── transform_silver.ipynb
│   ├── enrich_gold.ipynb
│   └── output/              # Auto-generated by orchestrate.py
│
├── src/
│   ├── utils/
│   │   ├── dataframe_utils.py     # Spark helpers
│   │   ├── request_utils.py       # API fetchers
│   │   ├── data_quality_utils.py  # Quality rules
│   │   └── path_utils.py          # Project path helpers
│
├── orchestrate.py           # Papermill-based orchestration

```

## 🚀 Features

- 📥 API Ingestion via YAML-configured endpoint
- 🧹 Silver-level cleaning and null handling
- 🧾 Gold-level enrichment with derived columns
- 📓 Notebook-driven ETL for transparency
- 📊 Data Quality Checks included
- ⚙️ Papermill-based orchestration
- 🔁 Configurable paths and filenames via JSON


## 🔧 Setup

### 🔹 Create Environment

```bash
conda create --name <<your-env-name>> python=3.10
conda activate <<your-env-name>>
pip install -r requirements.txt
```

> Optional: For running notebooks interactively
```bash
conda install ipykernel
python -m ipykernel install --user --name=<<your-env-name>> --display-name "<<your-env-name>>"
```

## ☕ Java Requirements

Ensure Java is available for Spark (Java 17) and paths are set

## 🧪 Running the Pipeline

### ▶️ Option 1: Via Notebooks

Run each notebook manually:

- `ingest_bronze.ipynb`
- `transform_silver.ipynb`
- `enrich_gold.ipynb`

### ▶️ Option 2: Papermill Orchestration

```bash
python orchestrate.py
```

This will inject paths and execute each notebook in order.


## 📊 Data Quality Checks

Implemented in `src/utils/data_quality_utils.py`:

- Check for nulls in critical fields
- Ensure valid age ranges and 2-letter state codes
- Raise descriptive exceptions if checks fail


## 📜 License

This project is licensed under the MIT License.  
See the [MIT License](LICENSE) file for full terms.

## 🤝 Contributing

Feel free to fork, suggest improvements, or open issues.  
This is designed as an open learning resource and modular data engineering foundation.
