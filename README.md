# 🏥 Health Insurance Rate Data Engineering Pipeline

This project provides a modular, production-grade data engineering pipeline to ingest, transform, and enrich U.S. health insurance rate data using Spark and Python. It follows the Bronze → Silver → Gold architecture and includes optional orchestration using [Papermill](https://papermill.readthedocs.io/en/latest/).

---

## 📁 Folder Structure

```css
health-insurance-rate-data-etl/
├── .gitignore
├── LICENSE                  # MIT license (see below)
├── README.md
├── requirements.txt
├── data/
│   ├── bronze/
│   ├── silver/
│   ├── gold
│   └── meta_data_files    
│ 
├── configurations/
│   └── config.json          # Paths and filenames config
│   ├── api_config.yaml      # API source configuration
│
├── notebooks/               # Jupyter notebooks for each pipeline stage
│   ├── ingest_bronze.ipynb
│   ├── transform_silver.ipynb
│   ├── enrich_gold.ipynb
│   └── output/              # Auto-generated by orchestrate.py
│
├── src/
│   ├── utils/
│   │   ├── dataframe_utils.py     # Spark helpers
│   │   ├── request_utils.py       # API fetchers
│   │   ├── data_quality_utils.py  # Quality rules
│   │   └── path_utils.py          # Project path helpers
│
├── orchestrate.py           # Papermill-based orchestration

```
---

## 🚀 Features

- 📥 API Ingestion via YAML-configured endpoint
- 🧹 Silver-level cleaning and null handling
- 🧾 Gold-level enrichment with derived columns
- 📓 Notebook-driven ETL for transparency
- 📊 Data Quality Checks included
- ⚙️ Papermill-based orchestration
- 🔁 Configurable paths and filenames via JSON

---

## 🔧 Setup

### 🔹 Create Environment

```bash
conda create --name hinsurance-etl python=3.10
conda activate hinsurance-etl
pip install -r requirements.txt
```

> Optional: For running notebooks interactively
```bash
conda install ipykernel
python -m ipykernel install --user --name=hinsurance-etl --display-name "Python (hinsurance-etl)"
```

---

## ☕ Java Requirements

Ensure Java 11 is available for Spark:

```bash
# View Java version
java -version

# On macOS, use Homebrew:
brew install openjdk@11
```

Set your environment:

```bash
export JAVA_HOME="/usr/local/opt/openjdk@11"
export PATH="$JAVA_HOME/bin:$PATH"
```

Or use a local JDK path via `.env` or hardcoded in `dataframe_utils.py`.

---

## 🧪 Running the Pipeline

### ▶️ Option 1: Via Notebooks

Run each notebook manually:

- `ingest_bronze.ipynb`
- `transform_silver.ipynb`
- `enrich_gold.ipynb`

### ▶️ Option 2: Papermill Orchestration

```bash
python orchestrate.py
```

This will inject paths and execute each notebook in order.

---

## 📊 Data Quality Checks

Implemented in `src/utils/data_quality_utils.py`:

- Check for nulls in critical fields
- Ensure valid age ranges and 2-letter state codes
- Raise descriptive exceptions if checks fail

---

## 📜 License

This project is licensed under the MIT License.  
See the [LICENSE](LICENSE) file for full terms.

---

## 🤝 Contributing

Feel free to fork, suggest improvements, or open issues.  
This is designed as an open learning resource and modular data engineering foundation.

---

## 👀 Roadmap

- ✅ Bronze → Silver → Gold data architecture implemented
- ✅ Config-driven API ingestion and transformation notebooks
- ✅ Papermill-based orchestration with parameter injection
- ✅ Basic data quality checks (nulls, formats, ranges)
- 🌟 Build GenAI-based Insurance Agent using LangChain/OpenAI (separate repo)